{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create SNN Model"
      ],
      "metadata": {
        "id": "pIDdqy0JMdQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install packages**"
      ],
      "metadata": {
        "id": "gNYEV2yxNCod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "!pip install git+https://github.com/miladmozafari/SpykeTorch.git\n",
        "import SpykeTorch.snn as snn\n",
        "import SpykeTorch.functional as sf"
      ],
      "metadata": {
        "id": "qsvyrbpaMg89",
        "outputId": "d635c0ab-9dc5-495d-cb6c-1589321e2807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/miladmozafari/SpykeTorch.git\n",
            "  Cloning https://github.com/miladmozafari/SpykeTorch.git to /tmp/pip-req-build-hbvvl3_0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/miladmozafari/SpykeTorch.git /tmp/pip-req-build-hbvvl3_0\n",
            "  Resolved https://github.com/miladmozafari/SpykeTorch.git to commit aa302c77cb61de6ec64e40927313137a9855ec6a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from SpykeTorch-miladmozafari==0.0.1) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from SpykeTorch-miladmozafari==0.0.1) (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from SpykeTorch-miladmozafari==0.0.1) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from SpykeTorch-miladmozafari==0.0.1) (10.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from SpykeTorch-miladmozafari==0.0.1) (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->SpykeTorch-miladmozafari==0.0.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->SpykeTorch-miladmozafari==0.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->SpykeTorch-miladmozafari==0.0.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->SpykeTorch-miladmozafari==0.0.1) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->SpykeTorch-miladmozafari==0.0.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->SpykeTorch-miladmozafari==0.0.1) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpykeTorch-miladmozafari==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpykeTorch-miladmozafari==0.0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpykeTorch-miladmozafari==0.0.1) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpykeTorch-miladmozafari==0.0.1) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpykeTorch-miladmozafari==0.0.1) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpykeTorch-miladmozafari==0.0.1) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpykeTorch-miladmozafari==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->SpykeTorch-miladmozafari==0.0.1) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->SpykeTorch-miladmozafari==0.0.1) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->SpykeTorch-miladmozafari==0.0.1) (1.3.0)\n",
            "Building wheels for collected packages: SpykeTorch-miladmozafari\n",
            "  Building wheel for SpykeTorch-miladmozafari (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SpykeTorch-miladmozafari: filename=SpykeTorch_miladmozafari-0.0.1-py3-none-any.whl size=27718 sha256=fb0261c5bcfc4b302d45d46c3923abf3e502215fb60fd929666bd2287ebe84b5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-17o7o__6/wheels/dc/1a/be/800ff08c666101c718fdfe0659a11e19c6fe7913e354fea6b4\n",
            "Successfully built SpykeTorch-miladmozafari\n",
            "Installing collected packages: SpykeTorch-miladmozafari\n",
            "Successfully installed SpykeTorch-miladmozafari-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create layers**"
      ],
      "metadata": {
        "id": "Z5tIEKQMPNbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DCSNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DCSNN, self).__init__()\n",
        "\n",
        "    #(in_channels, out_channels, kernel_size, weight_mean=0.8, weight_std=0.02)\n",
        "    self.conv1 = snn.Convolution(6, 30, 5, 0.8, 0.05)\n",
        "    self.conv2 = snn.Convolution(30, 250, 3, 0.8, 0.05)\n",
        "    self.conv3 = snn.Convolution(250, 200, 5, 0.8, 0.05)\n",
        "\n",
        "    #(conv_layer, learning_rate, use_stabilizer=True, lower_bound=0, upper_bound=1)\n",
        "    self.stdp1 = snn.STDP(self.conv1, (0.004, -0.003))\n",
        "    self.stdp2 = snn.STDP(self.conv2, (0.004, -0.003))\n",
        "    self.stdp3 = snn.STDP(self.conv3, (0.004, -0.003), False, 0.2, 0.8)\n",
        "    self.anti_stdp3 = snn.STDP(self.conv3, (0.004, -0.0005), False, 0.2, 0.8)"
      ],
      "metadata": {
        "id": "U7RvGNuSNG5Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create dictionary to save data during each forward pass while training**"
      ],
      "metadata": {
        "id": "R80oawo1YWjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_data(self, input_spk, pot, spk, winners):\n",
        "  self.ctx[\"input_spikes\"] = input_spk\n",
        "  self.ctx[\"potentials\"] = pot\n",
        "  self.ctx[\"output_spikes\"] = spk\n",
        "  self.ctx[\"winners\"] = winners"
      ],
      "metadata": {
        "id": "nt_2rmRiYkSw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create forward function**"
      ],
      "metadata": {
        "id": "a8LVW__LPS5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, input, max_layer):\n",
        "  input = sf.pad(input, (2, 2, 2, 2))\n",
        "  if self.training: # forward pass for training\n",
        "    pot = self.conv1(input)\n",
        "    spk, pot = sf.fire(pot, 15, True)\n",
        "    if max_layer == 1:\n",
        "      winners = sf.get_k_winners(pot, 5, 3)\n",
        "      self.save_data(input, pot, spk, winners)\n",
        "      return spk, pot\n",
        "    spk_in = sf.pad(sf.pooling(spk, 2, 2), (1, 1, 1, 1))\n",
        "    pot = self.conv2(spk_in)\n",
        "    spk, pot = sf.fire(pot, 10, True)\n",
        "    if max_layer == 2:\n",
        "      winners = sf.get_k_winners(pot, 8, 2)\n",
        "      self.save_data(spk_in, pot, spk, winners)\n",
        "    spk_in = sf.pad(sf.pooling(spk, 3, 3), (2, 2, 2, 2))\n",
        "    pot = self.conv3(spk_in)\n",
        "    spk = sf.fire_(pot)\n",
        "    winners = sf.get_k_winners(pot, 1)\n",
        "    self.save_data(spk_in, pot, spk, winners)\n",
        "    output = -1\n",
        "    if len(winners) != 0:\n",
        "      output = self.decision_map[winners[0][0]]\n",
        "    return output\n",
        "  else: # forward pass for testing\n",
        "    pot = self.conv1(input)\n",
        "    spk = sf.fire(pot, 15)\n",
        "    pot = self.conv2(sf.pad(sf.pooling(spk, 2, 2), (1, 1, 1, 1)))\n",
        "    spk = sf.fire(pot, 10)\n",
        "    pot = self.conv3(sf.pad(sf.pooling(spk, 3, 3), (2, 2, 2, 2)))\n",
        "    # omitting the threshold parameter means infinite threshold\n",
        "    spk = sf.fire_(pot)\n",
        "    winners = sf.get_k_winners(pot, 1)\n",
        "    output = -1\n",
        "    # each winner is a tuple of form (feature, row, column)\n",
        "    if len(winners) != 0:\n",
        "      output = self.decision_map[winners[0][0]]\n",
        "    return output"
      ],
      "metadata": {
        "id": "o-t65N9GPV84"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create STDP helper functions**"
      ],
      "metadata": {
        "id": "pCs_LLKAZF6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stdp(self, layer_idx):\n",
        "  if layer_idx == 1:\n",
        "    self.stdp1(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
        "  if layer_idx == 2:\n",
        "    self.stdp2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
        "\n",
        "def reward(self):\n",
        "  self.stdp3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
        "\n",
        "def punish(self):\n",
        "  self.anti_stdp3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])"
      ],
      "metadata": {
        "id": "-MLVw6gbZKBh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transform input images into spike waves**"
      ],
      "metadata": {
        "id": "8ojFajcuaKv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import SpykeTorch.utils as utils\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class InputTransform:\n",
        "  def __init__(self, filter):\n",
        "    self.to_tensor = transforms.ToTensor()\n",
        "    self.filter = filter\n",
        "    self.temporal_transform = utils.Intensity2Latency(15, to_spike=True)\n",
        "\n",
        "  def __call__(self, image):\n",
        "    image = self.to_tensor(image) * 255 # convert image to tensor\n",
        "    image.unsqueeze_(0) # add 1 extra time dimension\n",
        "    image = self.filter(image) # apply filter\n",
        "    image = sf.local_normalization(image, 8) # normalize\n",
        "    return self.temporal_transform(image) # generate spike wave tensor\n",
        "\n",
        "kernels = [utils.DoGKernel(3, 3/9, 6/9), utils.DoGKernel(3, 6/9, 3/9),\n",
        "           utils.DoGKernel(7, 7/9, 14/9), utils.DoGKernel(7, 14/9, 7/9),\n",
        "           utils.DoGKernel(13, 13/9, 26/9), utils.DoGKernel(13, 26/9, 13/9)]\n",
        "filter = utils.Filter(kernels, padding=6, thresholds=50)\n",
        "transform = InputTransform(filter)"
      ],
      "metadata": {
        "id": "zsrstV9naKUY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare MNIST Dataset"
      ],
      "metadata": {
        "id": "JZy2vw8tbtl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "data_root = \"./\"\n",
        "\n",
        "MNIST_train = utils.CacheDataset(MNIST(root=data_root, train=True, download=True, transform=transform))\n",
        "MNIST_test = utils.CacheDataset(MNIST(root=data_root, train=False, download=True, transform=transform))\n",
        "MNIST_loader = DataLoader(MNIST_train, batch_size=1000)\n",
        "MNIST_test_loader = DataLoader(MNIST_test, batch_size=len(MNIST_test))"
      ],
      "metadata": {
        "id": "acwnFChNbwEt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Test"
      ],
      "metadata": {
        "id": "HKsrEkjwc5us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unsupervised learning for normal STDP layers**"
      ],
      "metadata": {
        "id": "rfv15YlkdGRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "def train_unsupervised(network, data, layer_idx):\n",
        "  network.train()\n",
        "  for i in range(len(data)):\n",
        "    data_in = data[i].cuda() if use_cuda else data[i]\n",
        "    network(data_in, layer_idx)\n",
        "    network.stdp(layer_idx)"
      ],
      "metadata": {
        "id": "ZHr1x3-Dc65d"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reinforcement learning for R-STDP layer(s)**"
      ],
      "metadata": {
        "id": "xHaSMJ14eMQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def train_rl(network, data, target):\n",
        "  network.train()\n",
        "  perf = np.array([0, 0, 0]) # correct, wrong, silent\n",
        "  for i in range(len(data)):\n",
        "    data_in = data[i].cuda() if use_cuda else data[i]\n",
        "    target_in = target[i].cuda() if use_cuda else target[i]\n",
        "    d = network(data_in, 3)\n",
        "    if d != -1:\n",
        "      if d == target_in:\n",
        "        perf[0] += 1\n",
        "        network.reward()\n",
        "      else:\n",
        "        perf[1] += 1\n",
        "        network.punish()\n",
        "    else:\n",
        "      perf[2] += 1\n",
        "  return perf / len(data)"
      ],
      "metadata": {
        "id": "t6rDRifKeL4L"
      },
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}